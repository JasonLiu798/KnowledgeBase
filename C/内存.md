内存可以说是C和C++语言学习的关键点。
这里说一点我的理解，一家之言，欢迎拍砖哈。

内存要想理解透彻，首先要理解内存编址。即不同的内存条，内存模块，插到机器上，具体对应的内存地址是多少。

最开始的PC机，IBM PC XT，只有640k内存。IBM是这么规划的，最低的128k，是BIOS的地址，毕竟BIOS也是汇编语言，它也需要合法地址，才能被CPU正确运行。

512k~640k，被定义为端口映射地址，即这部分地址，可能对应某一个外设上的地址，方便程序直接访问设备。其中，最重要的，就是显卡，当初的显卡单元都比较小，如单色显卡只有2k显存，就映射在这个地址段。

呵呵，当年比尔盖茨，开了个世纪有名的黄腔，就是家用电脑，640k内存足以。就是这么来的，可现在呢？你的显存都不止640k，可见，伟人也有犯浑的时候。

这样显然不方便，因为就在几年后，286时代，内存已经1M了。
这就麻烦了，这1M的第一个128k不准用，中间还有个128k不准用，好端端的连续内存，就被切成两块，痛苦啊。

而那会CPU也是笨得可以，16位的CPU，Intel居然在PC XT上面用的是8位地址总线，这下死翘了，所有的内存被分割为64k一块块的小块，叫段。每个程序模块，必须小于64k，否则没法跳转。以前DOS下可以执行的二进制文件分为两种，com和exe，com就是不能大于64k的，因为它文件格式里面没有段修饰，因此，只能一段完成，64k。

这样，程序员十分的不方便，写程序，稍微大点的数组，就要考虑分段访问，没办法，数组下标不能超过64k。
另外，对于640k以上的地址访问，人们想出了一个很笨的方法，把640k~1024k这384k，也切成一块一块的，每块映射相同的内存区域，靠一个IO切换来访问不同的块。那会还没有想到更好的支持1M以上内存的方法，只能这么办。

这样，程序员成了个苦恼的职业，既要做软件编程，还要随时关注自己的数据是否越界，痛苦死了。当然，程序员也不会坐以待毙，这期间，他们自己想了很多方法，比如用底层模块来解决段切换问题，对上提供一层连续编址的虚拟地址来访问等等。

ok，到了80386，32位了，大家总算长出了一口气，这个CPU地址总线有32位，可以直接编址4G内存。
但是，问题来了，PC机已经做成这个样子了。当然，可以重新开发一款计算机，连续编址，4G内存，很爽，只是，这不是PC机了。

这又让人痛苦死了，明明有能力做连续编址，跨越段界限，但还是不能这么做，因为要支持老的程序。

程序员又开始想办法，基本思路就是用虚拟地址来代替实际地址，后来又想到了，既然都是虚拟的，那我们可不可以把一块磁盘文件也虚拟成内存，这样，我们给够4G，这不是更爽，底层再用一定算法来处理动态转换的效率优化。

这样，在93年左右吧，有一个很有名的C++语言，Watcom C++出世了。这个语言，是Dos下第一款支持4G内存的C++语言。这是Sybase开发的，它底层使用了一个虚拟内存管理模块，是另外一家公司开发的，叫Dos /4G，显然，就是DOS程序使用4G内存的解决方案。

还记得DOOM、C&C，红警，金庸群侠传不？当程序一运行，就会显示一行字“DOS /4GW ...”，这就是Watcom C++写的游戏。因为游戏界是最需要大内存的，贴图，声音的处理，都需要大数组，如果分块使用，程序员太累了，做不下来这么大的程序。

嗯，DOS/4GW，是DOS 4G的Watcom C++版本，因为真正的模块要收费的，这个版本是简化版，只能支持到256M内存，且不支持磁盘虚拟内存，不过不收费。不过，那个时代的应用也够了。

我以前写过Watcom C++的程序，呵呵，真的很爽。再也不考虑段指针之类的东东了，爽翻了。

后来就多了，gcc很早就有了的，99年的时候，gcc进攻DOS市场，出了个版本叫DJgpp，比Watcom C++还好用，我一用就爱上了，当时还把它的库函数手册翻译了一遍，算学习了。

不过，这个时间点，Windows95早出来了，Windows98也出来了，因此，DOS程序趋于没落。

早在Windows 1.1开发的时候(最早一个Windows版本，1.0没发布)，微软就知道，以后的操作系统要做到程序员友好才有生命力，而内存连续编址，就是最大的程序员友好。

因此，从一开始，Windows就使用了底层的内存支持技术，当Windows 3.1出世，其实Windows下开发程序，段的限制已经不是很明显了。

到Windows95，微软更是直接内置了类似于Dos /4GW之类的32位内存管理器，并内部直接包含虚拟内存和物理内存的自动切换算法，因此，从Windows 95以后，大家再开发程序，已经可以使用理论上长达4G的大数组了。

内存争议，至此告一段落。

现今32位的Windows系统，普遍支持4G内存，但，应用程序的空间只有2G。编址为低端地址，即0~2G的地址，为什么呢，因为高2G被系统占用，毕竟Windows系统那么多服务，也要运行，也需要地址空间。

Windows使用了类似切页的内存控制机制，每个应用程序，有2G的地址空间，上面2G是所有应用程序和系统共用。
呵呵，不止Windows，32位的Linux也有类似的设计。
因此，一个Windows应用程序最大能使用的内存，只有2G。

前面说的Ring0级的系统内核，一般都占用上2G的地址空间在运行。动态链接库dll，控件OCX，在调入内存中，由于要被多个进程看到，进程间重用，也是占用上面2G在运行。

这里就要说说钩子了，当我们想对一个应用程序下钩子，由于我们的程序和要勾的程序不在一个进程空间，因此，我们看到的内存是不一样的。就是它在20000这个地址单元看到的可能是个FF，而我们看到的可能是个00，因为这仅仅是逻辑地址一样，物理地址分属两个进程空间。
因此，如果要钩对方的消息，有个问题，钩到了，咋送回来？
一般的做法就是做个dll做中转站，钩子够到了，调用dll的函数，先存放到高端内存区，然后我们的程序再定时过去取，或者用回调什么的。
总之，如果要跨进程通讯，两个进程的共享内存区，一定是建立在高端的内存，就是2G以上的空间。

至于应用程序自己这2G，就看编译器咋使用了，一般都是，低端为栈空间，我们的函数代码，每次call一个函数，函数内部新建立的内部变量，是从低端向高处排。
而堆，则是从高处向底处排，啥时候，两个碰上了，啥时候，内存就满了，无法申请内存了。

栈又分为基栈和浮动栈，基栈就是编译期间就分配好了的内存。
全局变量，const的常量，static的变量，函数的代码，都是这部分。
浮动栈就是运行期间，根据函数，对象调用关系，动态分配的栈，类成员变量，函数内部变量，都是用的浮动栈。

void Func(void)
{
    char i=0;
    char* pBuffer=malloc(10);
    //...
}
这里面，Func的代码，在栈空间，其实是在基栈了。2G的最低
int i，这个i，在浮动栈。基站上方，也还是2G底部。
pBuffer指向的内存，由于是malloc，因此是堆空间，在2G的高端。

new和malloc其实是一样的，都是malloc的，但new支持对象，要自动调用构造函数。
不过这里也说明一点，new出来的对象，是运行期对象，其内部成员变量，其实是在2G的高端，堆空间里面。

写C和C++程序，需要对内存的分配非常敏感，随时关注自己使用的变量，是属于编译期间的基栈，还是运行期的浮动栈，还是堆。

比如，我们要启动一个线程，这个线程函数，肯定是在基栈了，编译器就定好的，但是我们希望线程访问一个运行期的动态地址，比如要传递一个参数给它。
我们就不能简单把一个函数内部的变量地址传给他，由于是函数内部变量属于浮动栈，函数返回，浮动栈就自动拆除，而线程启动是异步运算，就是一个函数启动线程，很可能这个函数已经返回了，线程还没有开始运行。
因此，就绝对不能使用函数内部变量给线程传参，只能使用堆空间，用malloc的一块地址来传参数，再由线程函数收到后，free掉。

这是唯一一个，不遵守“谁分配，谁释放”原则的特例。我把它叫做“远堆传参”。
很多初学线程的朋友，线程写出来就挂掉，就是这个地方出了问题。
但是，程序表面看起来一切正常，呵呵，所以内存很重要，因为它里面基本上都是隐式bug，很难用肉眼看代码看出来。

-----

一.首先， 在c中分为这几个存储区 
1.栈 - 由编译器自动分配释放 
2.堆 - 一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收 
3.全局区（静态区），全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。- 程序结束释放 
4.专门放字符串常量的地方。- 程序结束释放 
5 程序代码区，存放2进制代码。
                                                                                                                                               
在函数体中定义的变量通常是在栈上，用malloc, calloc, realloc等分配内存的函数分配得到的就是在堆上。在所有函数体外定义的是全局量，加了static修饰符后不管在哪里都存放在全局区（静态区）,在所有函数体外定义的static变量表示在该文件中有效，不能extern到别的文件用，在函数体内定义的static表示只在该函数体内有效。另外，函数中的"adgfdf"这样的字符串存放在常量区。比如： 

int a = 0; //全局初始化区 
char *p1; //全局未初始化区 
void main() 
{ 
    int b; //栈 
    char s[] = "abc"; //栈 
    char *p2; //栈 
    char *p3 = "123456"; //123456{post.content}在常量区，p3在栈上 
    static int c = 0; //全局（静态）初始化区 
    p1 = (char *)malloc(10); //分配得来得10字节的区域在堆区 
    p2 = (char *)malloc(20); //分配得来得20字节的区域在堆区 
    strcpy(p1, "123456"); 
    //123456{post.content}放在常量区，编译器可能会将它与p3所指向的"123456"优化成一块 
} 
 

二.在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区 
1.栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。 
2.堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。 
3.自由存储区，就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。 
4.全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 
5.常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改（当然，你要通过非正当手段也可以修改） 

三. 谈谈堆与栈的关系与区别 
具体地说，现代计算机(串行执行机制)，都直接在代码底层支持栈的数据结构。这体现在，有专门的寄存器指向栈所在的地址，有专门的机器指令完成数据入栈出栈的操作。这种机制的特点是效率高，支持的数据有限，一般是整数，指针，浮点数等系统直接支持的数据类型，并不直接支持其他的数据结构。因为栈的这种特点，对栈的使用在程序中是非常频繁的。对子程序的调用就是直接利用栈完成的。机器的call指令里隐含了把返回地址推入栈，然后跳转至子程序地址的操作，而子程序中的ret指令则隐含从堆栈中弹出返回地址并跳转之的操作。C/C++中的自动变量是直接利用栈的例子，这也就是为什么当函数返回时，该函数的自动变量自动失效的原因。 

和栈不同，堆的数据结构并不是由系统(无论是机器系统还是操作系统)支持的，而是由函数库提供的。基本的malloc/realloc/free 函数维护了一套内部的堆数据结构。当程序使用这些函数去获得新的内存空间时，这套函数首先试图从内部堆中寻找可用的内存空间，如果没有可以使用的内存空间，则试图利用系统调用来动态增加程序数据段的内存大小，新分配得到的空间首先被组织进内部堆中去，然后再以适当的形式返回给调用者。当程序释放分配的内存空间时，这片内存空间被返回内部堆结构中，可能会被适当的处理(比如和其他空闲空间合并成更大的空闲空间)，以更适合下一次内存分配申请。这套复杂的分配机制实际上相当于一个内存分配的缓冲池(Cache)，使用这套机制有如下若干原因： 
1. 系统调用可能不支持任意大小的内存分配。有些系统的系统调用只支持固定大小及其倍数的内存请求(按页分配)；这样的话对于大量的小内存分类来说会造成浪费。 
2. 系统调用申请内存可能是代价昂贵的。系统调用可能涉及用户态和核心态的转换。 
3. 没有管理的内存分配在大量复杂内存的分配释放操作下很容易造成内存碎片。 

堆和栈的对比 
从以上知识可知，栈是系统提供的功能，特点是快速高效，缺点是有限制，数据不灵活；而栈是函数库提供的功能，特点是灵活方便，数据适应面广泛，但是效率有一定降低。栈是系统数据结构，对于进程/线程是唯一的；堆是函数库内部数据结构，不一定唯一。不同堆分配的内存无法互相操作。栈空间分静态分配和动态分配两种。静态分配是编译器完成的，比如自动变量(auto)的分配。动态分配由alloca函数完成。栈的动态分配无需释放(是自动的)，也就没有释放函数。为可移植的程序起见，栈的动态分配操作是不被鼓励的！堆空间的分配总是动态的，虽然程序结束时所有的数据空间都会被释放回系统，但是精确的申请内存/ 释放内存匹配是良好程序的基本要素。 

    1.碎片问题：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出，详细的可以>参考数据结构，这里我们就不再一一讨论了。 
    2.生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。 
    3.分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。 
    4.分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。 

    明确区分堆与栈: 
    在bbs上，堆与栈的区分问题，似乎是一个永恒的话题，由此可见，初学者对此往往是混淆不清的，所以我决定拿他第一个开刀。 
    首先，我们举一个例子： 

void f() 
{ 
    int* p=new int[5]; 
} 
 
这条短短的一句话就包含了堆与栈，看到new，我们首先就应该想到，我们分配了一块堆内存，那么指针p呢？他分配的是一块栈内存，所以这句话的意思就是：在栈内存中存放了一个指向一块堆内存的指针p。在程序会先确定在堆中分配内存的大小，然后调用operator new分配内存，然后返回这块内存的首地址，放入栈中，他在VC6下的汇编代码如下： 
    00401028    push         14h 
    0040102A    call            operator new (00401060) 
    0040102F    add           esp,4 
    00401032    mov          dword ptr [ebp-8],eax 
    00401035    mov          eax,dword ptr [ebp-8] 
    00401038    mov          dword ptr [ebp-4],eax 
    这里，我们为了简单并没有释放内存，那么该怎么去释放呢？是delete p么？澳，错了，应该是delete []p，这是为了告诉编译器：我删除的是一个数组，VC6就会根据相应的Cookie信息去进行释放内存的工作。 
    好了，我们回到我们的主题：堆和栈究竟有什么区别？ 
    主要的区别由以下几点： 
    1、管理方式不同； 
    2、空间大小不同； 
    3、能否产生碎片不同； 
    4、生长方向不同； 
    5、分配方式不同； 
    6、分配效率不同； 
    管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。 
    空间大小：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）。当然，我们可以修改： 
    打开工程，依次操作菜单如下：Project->Setting->Link，在Category 中选中Output，然后在Reserve中设定堆栈的最大值和commit。 
注意：reserve最小值为4Byte；commit是保留在虚拟内存的页文件里面，它设置的较大会使栈开辟较大的值，可能增加内存的开销和启动时间。 
    堆和栈相比，由于大量new/delete的使用，容易造成大量的内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和核心态的切换，内存的申请，代价变得更加昂贵。所以栈在程序中是应用最广泛的，就算是函数的调用也利用栈去完成，函数调用过程中的参数，返回地址，EBP和局部变量都采用栈的方式存放。所以，我们推荐大家尽量用栈，而不是用堆。 

另外对存取效率的比较: 
代码: 

char s1[] = "aaaaaaaaaaaaaaa"; 
char *s2 = "bbbbbbbbbbbbbbbbb"; 
aaaaaaaaaaa是在运行时刻赋值的； 
而bbbbbbbbbbb是在编译时就确定的； 
但是，在以后的存取中，在栈上的数组比指针所指向的字符串(例如堆)快。 
    无论是堆还是栈，都要防止越界现象的发生（除非你是故意使其越界），因为越界的结果要么是程序崩溃，要么是摧毁程序的堆、栈结构，产生以想不到的结果,就算是在你的程序运行过程中，没有发生上面的问题，你还是要小心，说不定什么时候就崩掉,编写稳定安全的代码才是最重要的。 


static用来控制变量的存储方式和可见性 
       函数内部定义的变量，在程序执行到它的定义处时，编译器为它在栈上分配空间，函数在栈上分配的空间在此函数执行结束时会释放掉，这样就产生了一个问题: 如果想将函数中此变量的值保存至下一次调用时，如何实现？ 最容易想到的方法是定义一个全局的变量，但定义为一个全局变量有许多缺点，最明显的缺点是破坏了此变量的访问范围（使得在此函数中定义的变量，不仅仅受此 函数控制）。 
       需要一个数据对象为整个类而非某个对象服务,同时又力求不破坏类的封装性,即要求此成员隐藏在类的内部，对外不可见。 
       static的内部机制： 
       静态数据成员要在程序一开始运行时就必须存在。因为函数在程序运行中被调用，所以静态数据成员不能在任何函数内分配空间和初始化。 
       这样，它的空间分配有三个可能的地方，一是作为类的外部接口的头文件，那里有类声明；二是类定义的内部实现，那里有类的成员函数定义；三是应用程序的main（）函数前的全局数据声明和定义处。 
      静态数据成员要实际地分配空间，故不能在类的声明中定义（只能声明数据成员）。类声明只声明一个类的“尺寸和规格”，并不进行实际的内存分配，所以在类声 明中写成定义是错误的。它也不能在头文件中类声明的外部定义，因为那会造成在多个使用该类的源文件中，对其重复定义。 
      static被引入以告知编译器，将变量存储在程序的静态存储区而非栈上空间，静态数据成员按定义出现的先后顺序依次初始化，注意静态成员嵌套时，要保证所嵌套的成员已经初始化了。消除时的顺序是初始化的反顺序。 
       static的优势： 
       可以节省内存，因为它是所有对象所公有的，因此，对多个对象来说，静态数据成员只存储一处，供所有对象共用。静态数据成员的值对每个对象都是一样，但它的 值是可以更新的。只要对静态数据成员的值更新一次，保证所有对象存取更新后的相同的值，这样可以提高时间效率。 
        引用静态数据成员时，采用如下格式： 
         <类名>::<静态成员名> 
    如果静态数据成员的访问权限允许的话(即public的成员)，可在程序中，按上述格式 
来引用静态数据成员。 
       PS: 
      (1)类的静态成员函数是属于整个类而非类的对象，所以它没有this指针，这就导致 
了它仅能访问类的静态数据和静态成员函数。 
      (2)不能将静态成员函数定义为虚函数。 
      (3)由于静态成员声明于类中，操作于其外，所以对其取地址操作，就多少有些特殊 
，变量地址是指向其数据类型的指针 ，函数地址类型是一个“nonmember函数指针”。 

      (4)由于静态成员函数没有this指针，所以就差不多等同于nonmember函数，结果就 
产生了一个意想不到的好处：成为一个callback函数，使得我们得以将C++和C-based X W 
indow系统结合，同时也成功的应用于线程函数身上。 
      (5)static并没有增加程序的时空开销，相反她还缩短了子类对父类静态成员的访问 
时间，节省了子类的内存空间。 
      (6)静态数据成员在<定义或说明>时前面加关键字static。 
      (7)静态数据成员是静态存储的，所以必须对它进行初始化。 
      (8)静态成员初始化与一般数据成员初始化不同: 
      初始化在类体外进行，而前面不加static，以免与一般静态变量或对象相混淆； 
      初始化时不加该成员的访问权限控制符private，public等； 
           初始化时使用作用域运算符来标明它所属类； 
           所以我们得出静态数据成员初始化的格式： 
         <数据类型><类名>::<静态数据成员名>=<值> 
      (9)为了防止父类的影响，可以在子类定义一个与父类相同的静态变量，以屏蔽父类的影响。这里有一点需要注意：我们说静态成员为父类和子类共享，但我们有 重复定义了静态成员，这会不会引起错误呢？不会，我们的编译器采用了一种绝妙的手法：name-mangling 用以生成唯一的标志。









