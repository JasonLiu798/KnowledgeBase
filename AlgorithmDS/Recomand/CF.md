

[从理论到实践，一文详解 AI 推荐系统的三大算法](https://www.leiphone.com/news/201705/Gz6UinRrVKn0LLTe.html)

# CF 协同过滤算法
[推荐系统之协同过滤（CF）](http://lib.csdn.net/article/machinelearning/48966)
[推荐系统之协同过滤（CF）算法详解和实现](https://www.cnblogs.com/maybe2030/p/4636341.html)


用户 - 物品偏好的二维矩阵中，我们可以将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度

所有用户对某个物品的偏好作为一个向量来计算物品之间的相似度


---
# 协同过滤模型
## 基于邻域的方法
### 余弦相似度
向量夹角

### 皮尔逊相似度
协方差（Covariance）：反映两个随机变量相关程度的指标，如果一个变量跟随着另一个变量同时变大或者变小，那么这两个变量的协方差就是正值，反之相反

Pearson相关系数=协方差/两个变量的标准差

pearson是一个介于-1和1之间的值，当两个变量的线性关系增强时，相关系数趋于1或-1；
当一个变量增大，另一个变量也增大时，表明它们之间是
* 正相关：相关系数大于0；
* 负相关：一个变量增大，另一个变量却减小，相关系数小于0；
* 不存在线性相关关系：如果相关系数等于0

### 缺点
由于实际用户评分的数据是十分稀疏，用户之间可能根本没有相同的评论；
而且用启发式的方法很难考虑全面用户和物品之间的所有关系。


## 基于隐语义
不依赖于共同评分
将用户和物品分别映射到某种真实含义未知的feature向量。
用户feature代表用户对不同类别电影的喜好程度（如：动作片5，惊悚片5），物品feature代表电影中大致属于哪类电影（如：爱情片3，喜剧片5）。然后通过两个feature向量的内积来判断用户对一个物品的喜好程度。虽然这个方法不要求共同评分，但推荐系统还是面临很大的数据稀疏问题。



---
# K-means
聚类
按照数据的属性通过K-Means算法把数据先分成几大类，然后再在每个大类中通过邻域或是隐语义算法进行推荐

* 随机取k个种子点
* 求其他点到k个种子点的距离，距离近的移为点群
* 移动种子点到点群中心
* 重复2,3，知道种子点不再移动

## 缺点
* 最大问题是：K值对最后的结果影响较大，但是该值是由用户确定的，且不同的数据集，该值没有可借鉴性 
* 对离群数据点敏感，就算少量的离群数据也能对结果造成较大的影响 
* 算法初始化中心点的选择好坏，会直接影响到最终程序的效率
为了解决上面的问题，出现了二分KMeans算法，有兴趣的读者，可以自行寻找相关的资料 ，本文不做详细介绍

---
# SVD
特征值分解是一个提取矩阵特征很不错的方法，但是它只是对方阵而言的。

[奇异值分解（SVD）](https://zhuanlan.zhihu.com/p/29846048)
[SVD 降维体现在什么地方？](https://www.zhihu.com/question/34143886)

## 奇异值分解
在现实的世界中，我们看到的大部分矩阵都不是方阵，比如说有N个学生，每个学生有M科成绩，这样形成的一个N*M的矩阵就不可能是方阵，我们怎样才能描述这样普通的矩阵呢的重要特征呢？奇异值分解可以用来干这个事情，奇异值分解是一个能适用于任意的矩阵的一种分解的方法。

A=UΣV^T
假设：
* A是一个N * M的矩阵
* 那么得到的U是一个N * N的方阵（里面的向量是正交的，U里面的向量称为左奇异向量）
* Σ是一个N * M的矩阵（除了对角线的元素都是0，对角线上的元素称为奇异值）
* V’(V的转置)是一个N * N的矩阵，里面的向量也是正交的，V里面的向量称为右奇异向量）

将一个矩阵A的转置 *A，将会得到一个方阵，我们用这个方阵求特征值可以得到： 
(A^T A)v_i=\lambda_i v_i


































