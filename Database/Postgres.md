

在 Postgres，主索引和二级索引都指向磁盘上的 tuple 偏移。当一个 tuple 的位置变化，各项索引都必须更新。





---
#Postgres 上述设计的大坑
##1. 写放大（Write Amplification）
通常的写入放大是指一种问题数据写入，比如在 SSD 盘上，一个小逻辑更新（例如，写几个字节）转换到物理层后，成为一个更大的更昂贵的更新。
比如修改 al-Khwārizmī 的出生年份时，我们不得不执行至少四个物理的更新：
在表空间中写入新行的 tuple；
为新的 tuple 更新主键索引；
为新的 tuple 更新姓名索引 (first, last) ；
更新 birth_year 索引，为新的 tuple 添加一条记录；
事实上，这四步更新仅为了反映一个到主表的写操作；并且每个这些写入也同样需要在 WAL 得到体现，所以在磁盘上写入的总数目甚至比 4 步更大。

值得一提的是这里更新 2 和 3。当我们更新了 al-Khwārizmī 的出生年份，我们实际上并没有改变他的主键，我们也没有改变他的名字和姓氏。然而，这些索引仍必须与创建在数据库中的行记录了新的行的 tuple 的更新。对于具有大量二级索引的表，这些多余的步骤可能会导致巨大的低效。举例来说，如果我们有一个表上定义了十几个二级索引，更新一个字段，仅由一个单一的索引覆盖必须传播到所有的 12 项索引，以反映新行的 CTID。

##2. 复制
因为复制发生在磁盘的变化上，因此写入放大问题自然会转化为复制层的放大。
一个小的逻辑记录，如“更改出生年份为 CTID D 到 770”，WAL 会将上述描写的 4 步从网络上同步到从库，因此写入放大问题也等同一个复制放大问题，从而 Postgres 的复制数据流很快变得非常冗长，可能会占用大量的带宽。

在 Postgres 的复制发生一个数据中心内的情况下，复制带宽可能不是一个问题。现代网络设备和交换机可以处理大量的带宽，许多托管服务提供商提供免费或廉价的内部数据中心带宽。然而，当复制必须在不同数据中心之间发生的，问题都可以迅速升级。

例如，Uber 原本使用的物理服务器在西海岸机房。为了灾难恢复的目的，我们在东海岸托管空间添加了一批服务器。在本设计中，我们西部数据中心作为主库，东海岸增加了一批服务器作为从库。

级联复制可以降低跨数据中心的带宽要求，只需要主库和一个从库之间同步一份数据所需的带宽和流量，即便在第二个数据中心配置了多个从库。然而，Postgres 的复制协议的详细程度，对于使用了大量二级索引的数据库，仍可能会导致数据的海量传输。采购跨国的带宽是昂贵的，即使有钱的土豪公司，也无法做到跨国的带宽和本地的带宽一样大。

这种带宽的问题也导致我们曾经在 WAL 归档方面出现过问题。除了发送所有从西海岸到东海岸的 WAL 更新，我们将所有的 WAL 记录归档到一个文件存储的 Web 云服务，这样当出现数据灾难情况时，可以从备份的 WAL 文件恢复。但是流量峰值时段，我们与存储网络服务的带宽根本无法跟上 WAL 写入的速度。

##3. 数据损坏
在一次例行主数据库扩容的变更中，我们遇到了一个 Postgres 9.2 的 bug。
从库的切换时间顺序执行不当，导致他们中的一些节点误传了一些 WAL 记录。因为这个 bug，应该被标记为无效的部分记录未标记成无效。

以下查询说明了这个 bug 如何影响我们的用户表：
SELECT * FROM users WHERE ID = 4;

此查询将返回两条记录：修改出生年份之前的老记录，再加上修改后的新记录。如果将 CTID 添加到 WHERE 列表中，我们将看到返回记录中存在不同的 CTID 记录，正如大家所预料的，返回了两个不同行的 tuple。

这个问题是有几个原因非常伤脑筋。首先，我们不能轻易找出这个问题影响的行数。从数据库返回的结果重复，导致应用程序逻辑在很多情况下会失败。我们最终使用防守编程语句来检测已知有这个问题表的情况。
因为 bug 影响所有服务器，损坏的行在不同的服务器节点上可能是不同的，也就是说，在一个从库行 X 可能是坏的，Y 是好的，但对另一个从库，用行 X 可能是好的，Y 行可能是坏。事实上，我们并不确定数据损坏的从库节点数量，以及主库是否也存在数据损坏。

虽然我们知道，问题只是出现在每个数据库的少量几行，但我们还是非常担心，因为 Postgres 复制机制发生在物理层，任何小的错误格式有可能会导致彻底损坏我们的数据库索引。
B 树的一个重要方面是，它们必须定期重新平衡 ，并且这些重新平衡操作可以完全改变树的结构作为子树被移到新的磁盘上的位置。
如果错误数据被移动，这可能会导致树的大部分地区变得完全无效

最后，我们追踪到了实际的 bug，并用它来确定新的 master 不存在任何损坏行。然后再把 master 的快照同步到所有从库上去，这是一个艰苦的体力活的过程（小编：看到美帝的 DBA 也这么苦逼心理终于平衡一点了），因为我们每次只能从在线的池子里面拿出有限几台来操作。

虽然我们遇到的这个 bug 仅影响 Postgres 9.2 的某些版本，而且目前已经修复了很久。但是，我们仍然发现这类令人担忧的 bug 可以再次发生。可能任意一个新的 Postgres 版本，它会带着这种致命类型的 bug，而且由于其复制的不合理的设计，这个问题一旦出现，就会立即蔓延到集群中所有复制链的数据库上。

##4. 从库无 MVCC
Postgres 没有真正的从库 MVCC 支持。在从库任何时刻应用 WAL 更新，都会导致他们与主库物理结构完全一致。这样的设计也给 Uber 带来了一个问题。

为了支持 MVCC，Postgres 需要保留行的旧版本。如果流复制的从库正在执行一个事务，所有的更新操作将会在事务期间被阻塞。在这种情况下，Postgres 将会暂停 WAL 的线程，直到该事务结束。但如果该事务需要消耗相当长的时间，将会产生潜在的问题，Postgres 在这种情况下设定了超时：如果一个事务阻塞了 WAL 进程一段时间，Postgres 将会 kill 这个事务。

这样的设计意味着从库会定期的滞后于主库，而且也很容易写出代码，导致事务被 kill。这个问题可能不会很明显被发现。例如，假设一个开发人员有一个收据通过电子邮件发送给用户一些代码。这取决于它是如何写的，代码可能隐含有一个的保持打开，直到邮件发送完毕后，再关闭的一个数据库事务。虽然它总是不好的形式，让你的代码举行公开的数据库事务，同时执行无关的阻塞 I / O，但现实情况是，大多数工程师都不是数据库专家，可能并不总是理解这个问题，特别是使用掩盖了低级别的细节的 ORM 的事务。（小编：美帝程序员代码习惯跟咱们也很类似）

---
#Postgres 的升级
因为复制记录在物理层面工作，这导致不能在不同的 Postgres GA 版本之间进行复制。运行的 Postgres 9.3 主数据库无法复制数据到 Postgres 9.2 的从库上，也无法在运行 9.2 的主数据库复制数据到 Postgres 9.3 的从库上。

我们按照以下这些步骤，从一个 Postgres 的 GA 版本升级到另一个：
关闭主数据库。
在主库上运行 pg_upgrade 命令，这是更新主库数据的命令 。在一个大的数据库上，这很容易需要几个小时的时间，执行期间不能够提供任何访问服务。
再次启动主库。
创建主库的新快照，这一步完全复制一份主库的所有数据，因此对于大型数据库，它也需要几个小时的时间。
清除所有从库上的数据，将从主库导出的快照恢复到所有从库。
把每个从库恢复到原先的复制层次结构。等待从库追上主库的最新的更新数据。

我们使用上述方法将 Postgres 9.1 成功升级到 Postgres 9.2。然而，这个过程花了太多时间，我们不能接受这个过程再来一次。到 Postgres 9.3 出来时，Uber 的增长导致我们的数据大幅增长，所以升级时间将会更加漫长。出于这个原因，我们的 Postgres 的实例一直运行 Postgres 9.2 到今天，尽管当前的 Postgres GA 版本是 9.5。

如果你正在运行 Postgres 9.4 或更高版本，你可以使用类似 pglogical，它实现了 Postgres 的一个逻辑复制层。使用 pglogical，可以在不同的 Postgres 版本之间复制数据，这意味着升级比如从 9.4 到 9.5，不会产生显著的停机时间。但这个工具的能力依然存疑，因为它没有集成到 Postgres 主干，另外对于老版本的用户，pglogical 仍然不能支持。






















