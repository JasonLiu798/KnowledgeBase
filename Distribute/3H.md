#big data
---
#微信
[微信春晚红包的10亿个红包，技术架构到底难在哪儿？](http://www.2cto.com/weixin/201503/381411.html)
[微信产品经理和架构师们是靠什么扛住了10亿个红包？](http://www.woshipm.com/pmd/138987.html)
[微信红包系统设计 & 优化](http://www.kuqin.com/shuoit/20150402/345538.html)
[首发：春晚微信红包，是怎么扛住一百亿次请求的？](http://www.chinaz.com/manage/2015/0720/424701.shtml)
[大数据生态圈](http://blog.csdn.net/jiyiqinlovexx/article/details/45851961)



##有损服务
拆分产品流程，选择性牺牲一部分数据一致性和完整性从而保证核心功能绝大多数运行。
任何关联系统出现异常的时候马上进行系统降级，防止引起系统雪崩
系统降级：
1.核心功能分拆和简化，通过辅助轻量化的服务实现，确保最短关键路径的可行，比方说在接入层置入摇红包逻辑，将每秒千万级请求转化为每秒万级的红包请求，再传到红包服务的后端逻辑，降低雪崩的可能性。
后端采用异步分拆，接收到用户请求时仅进行合法性验证，验证完成后直接告知成功，后续业务逻辑进入异步队列进行处理，减少了用户的等待时间，也极大降低了峰值雪崩的概率。
接入服务----->简化版服务---->异步队列----->耗时操作（前端提醒）

过载保护措施。客户端已提前预埋了策略，在连接失败或超时情况下会有相应提示，减少用户重复请求次数。
接入层，针对频繁发出请求的客户端限制响应速度，并对系统负载划分出若干等级，达到不同阈值时引导客户端使用不同限速速率

在异常情况出现时，采取减少红包数，异步限流降低拆/分享红包的速率等措施减轻服务器端压力；与此同时，微信红包还有全程压测流程，对整个业务链接进行自动提前评估，防止过载。

##柔性可用
有损服务价值观支持下的方法，重点在于实际上会结合用户使用场景，根据资源消耗，调整产品策略，
不同级别的用户体验场景，保证尽可能成功返回关键数据，并正常接受请求，绝不轻易倒下
1、系统容灾：面对大规模的请求量，系统容灾必不可少，容灾一般可分为逻辑层容灾和数据层容灾，这次微信后台开发团队在容灾布置中采用30%切换的逻辑层方案，即核心服务都能做到最多1/3服务器出问题的情况下自动容灾切换以保证服务质量，提高预警级别换取系统的可用性。
2、资源隔离：顾名思义就是把资源进行隔离减少服务支路间的影响，从逻辑入手，在资源逻辑中，当A服务同时分派任务给BC服务时，设定单个最大分配上限值，避免任意一个支路出问题影响整个服务链条，这样即使部分服务出现问题也不会影响到整个服务的崩塌。
3、快速拒绝：当服务过载时尽早拒绝请求，由服务调用方换机重试避免单一服务器重试过载，快速拒绝和有损服务中的及早拒绝是一个概念的方法，从过程的源头将问题解决，成本越低，影响越小，前端保护后端的方式来解决问题。
4、支付分组：从支付环节入手，将所有红包分为50个组，放在50个单独的set上互不影响，单组set出问题最多只影响1/50用户，保证多数人服务不受干扰。分组set化也是柔性可用的一个重要技术手段，这一思维非常类似于现实生活中的集装箱思维——通过标准化，规模化的箱体设计，应对复杂多样的货物，使每个流通环节既独立又不失灵活。
5、流量预加载：从客户端入手，将语音图片等极消耗流量的资源提前让客户端自动下载预置好，提前将流量洪峰疏导，并在活动当天CDN将准备数百G带宽应对，这块也与过载保护中的快慢分离是相通的，将耗流量的服务提前加载避免高峰期间的冲突。

##大系统小做
大系统小做应该来说，是一种意识，他的核心思想是将功能复杂较大的系统，化大为小，减少模块耦合，降低关联性，用多个独立的模块来实现整体系统的功能，大系统小做采用的是化繁为简，分而治之，便于开发和迅速实现。
减少依赖，隔离影响，灰度服务




---
#spark
##BDAS
Spark Streaming[流式计算] SparkSQL[] GraphX[图计算引擎] MLlib[机器学习库]
spark[计算引擎]
tachypon[分布式内存邮件系统]    hdfs[存储层]
mesos[资源管理]


##spark组成
###ClusterManager
standalone模式中为Master，监控整个集群，监控Worker；YARN模式中为资源管理器
###Worker
负责控制计算节点，启动Executor和Driver；YARN模式为NodeManager，计算节点控制
###Driver
运行Application得Main函数，创建SparkContext
###Excutor
某个Application运行在worker node上得一个进程，启动线程池运行任务，每个Application有独立一组executors

spark context:控制应用生命周期
RDD:基本计算单元，有向无环图RDD Graph
DAG Scheduler
TaskScheduler
SparkEnv：线程级别上下文



旧有
重复开发
系统组合
专有系统适用范围局限
资源分配管理

优势：
多计算范式
处理速度
易用性 多语言支持
兼容性 与hdfs兼容
社区活跃度高

##程序示例
输入构造RDD
转换Transformation
输出Action

##弹性分布式数据集RDD
partition(a list of partitions)
compute(function fro computing each split)
dependencies(a list of dependencies on other RDDs)
partitioner
preferredLocation 

##RDD两类基础函数
1)Transformations
延迟计算
map
filter
reduseByKey
2)Actions
触发spark提交作业(Job)，数据输出到系统
redusce(func)
collect
count
first
take

##开发
intellij
SBT插件 Scala插件
















