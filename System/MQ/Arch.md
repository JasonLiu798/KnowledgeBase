

#消息可靠性
消息可靠的定义就是消息不丢失，不丢失意味着两个方面：
* 消息本身不丢失
* 消息能被消费到（不然也没意义）

能影响消息可靠性的包括如下三个部分：
Producer（生成者）
Consumer（消费者）
Store（存储）
很大一部分情况下，消息的可靠性不会有什么问题，异常时候才是考验的时候，一般面对异常的有如下几种情况：
* Producer/Consumer App Crash
* Broker Crash
* OS Crash
* Disk/Machine故障
* 断电
* 网络异常（比如超时）

##Producer
Producer的使用场景有两类，分别是事务写入和业务之后的写入，比如：
def foo():
  // do biz logic
  if (biz logic result):
   producer->send(msg)
对于普通的写入，有两种可能，如下：
###消息没机会发送（业务执行完成）
可能原因：App Crash、OS Crash、机器故障、断电
对于这种情况，业务已经执行成功，但是准备执行发送的时候，出现异常。
处理方式：
无法处理，一般情况下，出现这种可能性非常低，因为发送的整个过程一般也就5ms以内。

解决办法：
可以先写一条日志，状态为未确认，发送后更新状态为确认，定时检查日志中状态为失败的，重新执行

###消息发送失败
可能原因：网络异常、Broker异常
处理方式：交给业务方自己处理
对于事务发送，各种情况就无需担心了，一般过程如下：
1.发送一条状态为”Ready”的消息
2.Broker存储这条消息，并且写入Redo Log，事务队列
3.返回给Producer发送状态
4.Producer执行本地业务逻辑（比如写入DB之类的）
5.根据Producer的写入结果，发送一条消息状态为”Commit”或”Rollback”
6.Broker根据消息，进行对应commit（写入消费队列）或rollback（回滚事务）
对于一种情况就是，在进行commit或rollback的时候，业务故障了，可以通过回查去解决，关于事务的具体实现，之后再撰文记录。
事务的出现就是解决一致性问题，理论上，无论哪个步骤出现问题，都不会有影响。

##Broker
前提：对于存储来说，没有备份，可用性为0，所以对于重要业务而言，至少是一主一备，敏感业务可能一主两备。
这儿涉及到写入存储的方式，一般有三种：
1.同步单写：写入Disk后，才响应Client
2.同步双写：写入Disk，且写入两台（一主一备）后，才响应client
3.异步写入：写入Page Cache后，就响应client，异步刷盘
一般的写入流程如下：
```
Producer               
          +                  
          |                  
          |                  
          |                  
          v                  
                             
+-------------------------------+
|            JVM Heap           |
+--+----------------------------+
   |                             
   v                  ^      
                      |      
+-------------------------+-----+
|            Page Cache         |
+--+----------------------------+
   |                             
   v                  ^      
                      |      
+-------------------------+-----+
|             Disk              |
+-------------------------------+
```
但是通过Zero Copy，在Broker端，消息是无需进入JVM Heap的，所以现在也就是只需要考虑写入Page Cache和Disk了。

通过上面可以知道，对于同步（包括双写）而言，是不会丢失消息的，因为如果写入过程没有完成就异常，则响应client会告知失败。

对于异步写入，会存在数据丢失的风险，毕竟依赖后台线程刷盘，但是如果刷盘控制合理，丢失的量会很少。

结论：
1.没有完全的方案
2.对于敏感业务，同步双写最为妥当（但是性能会比较差）
3.对于一般业务，同步写入即可
4.对于消息安全不那么敏感的业务，可以异步写入（这样单点吞吐可以提升不少）
Broker主要是负责消息安全中的不丢失原则。

##Consumer
Consumer需要考虑消息安全性中的消息能被消费到这个原则。Consumer Client的设计一般参考Reactor，即I/O与计算分离，也就是说，Consumer一般由下面两个组件组成（仅考虑Pull模式）：
Pull组件：负责拉消息，然后写入Consume组件
Consume组件：负责消费
一般暴漏给用户的消费API如下：
```java
public interface Consume {
  ConsumeResult consume(Message msg);
}

/**
 * 消费结果，用于Client确认消费进度
 */
public enum ConsumeResult {
  
  CONSUME_RESULT_SUCCESS,
  
  CONSUME_RESULT_FAIL
}
```
消费进度提交的原则如下：只有消费成功了，才会刷新消费进度，并且消费进度保存在Broker。所以无论是出现上面异常中的哪一些，都没有问题，最多就是重复消费的问题。
主要处理消费失败的问题，也就是说，对于某个（批）消息，消费失败且API返回ConsumeReuslt.CONSUME_RESULT_FAIL。
对于消费失败，有三种可能：
* 消息本身有问题，所以消费失败
* 消息本身没问题，但是消费依赖时间（比如有状态，或依赖的第三方组件挂了，需要等待恢复），那么需要稍后重试
* 消息本身没问题，但是消费API有Bug，导致一直失败
个人能想到的处理原则是，及时真的没法儿消费成功，也要让用户知道是哪些没成功。所以，针对上面的三种情况，处理思路如下：
ConsumeResult增加一个新值，叫”CONSUME_RESULT_TRY_AGAIN_LATER”，如果消费API返回此值，则通过Scheduler发布一个新的延迟消费事件

如果Client返回的值是CONSUME_RESULT_FAIL（或者NULL），则此时有四种可能：
* Client依赖的第三方组件挂了（比如DB、Cache，这种情况下，消费失败可能会比较久）
* 没考虑到这种情况，逻辑错误
* 消息本身错误，比如解码的时候就异常了
* 消费过程中抛出了异常，被Client捕获

这儿要面对两种情况：
顺序消费：从目前的设计来看，能做的就是定期的轮询消费，因为不能跳。一种极端的情况是，该Queue就无法被消费了，这个时候就只能人工来处理了，MQ要做的就是能捕获这种情况，以及对应失败的消息。
无序消费：最大的优势就是“跳过”，我们假设当前消费失败只是偶然的（虽然可能是持续的）。存储好跳过的消息，后续再消费即可。
对于这批消息，可能下一次就消费成功了，也可能持续失败，对于持续失败的消息，需要同时用户。对于这个Consumer订阅的Topic，都自动生成一个消费败，一个消费持续失败的队列（消费失败超过指定次数）。对于每一个Consumer而言，订阅了指定Topic，就是自动订阅该Topic对应的消费失败Topic，从而达到重复消费的目的。

至此，通过上面的设计保证了消息安全性中的一定被消费的原则。











