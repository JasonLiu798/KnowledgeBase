#Crawl
---
#http请求
urllib2
requests

---
#页面解析
BeautifulSoup

XPATH
http://www.w3school.com.cn/xpath/xpath_syntax.asp
lxml

----
#JS解析
##casperjs
[down](http://casperjs.org/)

##Phantomjs
[down](http://phantomjs.org/download.html)
安装：配置bin PATH环境变量



---
#并行
threading
Celery - 分布式任务队列
[Bloom Filter: Bloom Filters by Example](http://billmill.org/bloomfilter-tutorial/)

---
#验证码
##图形库
PIL
opencv
##机器学习
pybrain

---
#all
scrapy
Kimono : Turn websites into structured APIs from your browser in seconds

----
#实例
淘宝爬虫
http://blog.chinaunix.net/uid-23500957-id-3858913.html
http://www.zhihu.com/question/36338520#answer-22827812

#distribute_crawler
这是用scrapy,redis, mongodb,graphite实现的一个分布式网络爬虫 ，如果爬取知乎或是豆瓣这种网页数量庞大的网站，还是用分布式吧，不然你只能 眼看着花谢花开，爬虫根本停不下来

#portia
这是一个可视化爬虫，基于Scrapy，我在本地跑过，蛮有意思的。它提供了可视化操作的Web页面，你只需点击页面上你要抽取的数据就行，这种方式可能蛮招geek嫌弃的（什么！！你居然让我用图形界面！！） 不过上手简单，效果明显，开始不容易乏味，可以作为正式学习爬虫前的娱乐

#pyspider
让你在WEB 界面编写调试脚本，监控执行状态，查看历史和结果 ，你可以在线试下demo：Dashboard - pyspider


* 首先极力推荐，github上很火的 awesome-awesomeness  ，前段时间github上冒出许多高关注的awesome-*项目，而 awesome-awesomeness 是对这些项目的汇总，就是说它是一个汇总资源汇总项目的项目，蛮拗口的是吧，其中就包括了对机器学习的汇总链接 Machine Learning 以及数据科学的链接 Data Science 。 从mooc视频到工具集应有尽有


* 另外，之前知乎上有个很棒的回答，已经做了很好的总结了 在数据分析、挖掘方面，有哪些好书值得推荐？ 我自己学习的入门书恰好也都在里边，像Python for Data Analysis 和集体智慧编程，这两本书我都很喜欢，至于学习爬虫的话，直接参考Scrapy官方文档就行


---
#todo
谷阿莫
http://space.bilibili.com/space?uid=8578857&page=1
https://www.zhihu.com/question/36338520#answer-22827812

[java爬虫](http://www.open-open.com/68.htm)






